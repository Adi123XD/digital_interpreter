{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcb698c-3ed0-4480-ae4f-0d955ce30f36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72352f0e-e5b8-4994-ad0b-ced20d9a4b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1759b9-90cb-455a-840b-0268bfbf577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee95cf6-879d-4ca6-8a3f-55e3506eb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(min_detection_confidence=0.8,min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret,frame= cap.read()\n",
    "        \n",
    "        # bgr to rgb\n",
    "        image = cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
    "        image=cv2.flip(image,1)\n",
    "        h,w,c=image.shape\n",
    "        \n",
    "        # set flag to false\n",
    "        image.flags.writeable =False\n",
    "\n",
    "        #Detections\n",
    "        results = hands.process(image)\n",
    "\n",
    "        #set flag back to true\n",
    "        image.flags.writeable =True\n",
    "\n",
    "        #rgb to bgr\n",
    "        image = cv2.cvtColor(image , cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmark in results.multi_hand_landmarks:\n",
    "                for idx , lm in enumerate(hand_landmark.landmark):\n",
    "                    if (idx==8):\n",
    "                        cv2.circle(image,(int(lm.x*w),int(lm.y*h)),15,(255,0,0),cv2.FILLED)\n",
    "                mp_drawing.draw_landmarks(image , hand_landmark, mp_hands.HAND_CONNECTIONS,\n",
    "                                          mp_drawing.DrawingSpec(color=(121,22,76),thickness=2,circle_radius=4),\n",
    "                                          mp_drawing.DrawingSpec(color=(255,255,255),thickness=2,circle_radius=2))\n",
    "                    \n",
    "               \n",
    "        cv2.imshow(\"Hands Tracking\" ,image)\n",
    "        if (cv2.waitKey(1) ==27):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c6edada-23ed-4277-accd-0478c114560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[classification {\n",
      "  index: 1\n",
      "  score: 0.9908215403556824\n",
      "  label: \"Right\"\n",
      "}\n",
      "]\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# print(results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.WRIST])\n",
    "print(results.multi_handedness)\n",
    "for num , classification in enumerate (results.multi_handedness):\n",
    "    # print(classification.classification)\n",
    "    print(num)\n",
    "    print(classification.classification[0].index)\n",
    "    # if (num ==classification.classification[0].index):\n",
    "    #     print(\"yes\")\n",
    "    #     print((classification.classification[0].label), \"hand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdfb49ae-d549-4f67-a9af-bb5c16108fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandLandmark.WRIST\n"
     ]
    }
   ],
   "source": [
    "print(mp_hands.HandLandmark.WRIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a270c-3e6c-4c45-9852-42ea56d3fc83",
   "metadata": {},
   "source": [
    "## Detect left and right hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13763642-f19c-44b6-b7d5-34e7646870e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(index,hand,results):\n",
    "    output =None\n",
    "    for idx,classification in enumerate(results.multi_handedness):\n",
    "        print(index)\n",
    "        if classification.classification[0].index ==index:\n",
    "            label = classification.classification[0].label\n",
    "            print(label ,\"match\")\n",
    "            score = classification.classification[0].score\n",
    "            text ='{} {}'.format(label , round(score,2))\n",
    "        #Extract the coordinates\n",
    "            coord = tuple (np.multiply(\n",
    "                np.array((hand.landmark[mp_hands.HandLandmark.WRIST].x,hand.landmark[mp_hands.HandLandmark.WRIST].y)),[640,480]).astype(int))\n",
    "            output=text , coord\n",
    "    return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8baf691c-8f83-4243-b4ed-0d5c2904a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "1\n",
      "1\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n",
      "0\n",
      "Left match\n"
     ]
    }
   ],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(min_detection_confidence=0.8,min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret,frame= cap.read()\n",
    "        \n",
    "        # bgr to rgb\n",
    "        image = cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
    "        image=cv2.flip(image,1)\n",
    "        \n",
    "        # set flag to false\n",
    "        image.flags.writeable =False\n",
    "\n",
    "        #Detections\n",
    "        results = hands.process(image)\n",
    "\n",
    "        #set flag back to true\n",
    "        image.flags.writeable =True\n",
    "\n",
    "        #rgb to bgr\n",
    "        image = cv2.cvtColor(image , cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        #rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num , hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image , hand, mp_hands.HAND_CONNECTIONS,\n",
    "                                         mp_drawing.DrawingSpec(color=(121,22,76),thickness=2,circle_radius=4),\n",
    "                                         mp_drawing.DrawingSpec(color=(255,255,255),thickness=2,circle_radius=2))\n",
    "                if get_label(num , hand , results):\n",
    "                    text ,coord = get_label(num , hand , results)\n",
    "                    cv2.putText(image, text,coord,cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "        #Save the images\n",
    "        # cv2.imwrite(\n",
    "        #     os.path.join(\"Output Images\" , '{}.jpg'.format(uuid.uuid1())),image)\n",
    "        cv2.imshow(\"Hands Tracking\" ,image)\n",
    "        if (cv2.waitKey(1) ==27):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dceabd1-a7b7-4370-9023-3358d84ee587",
   "metadata": {},
   "source": [
    "## detect left and rigth hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c490cd-dd54-427c-bf5a-3cfaa932fb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4c0f32c-dc76-4106-8a6c-dc0decf2a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label(num , hand , results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199c042a-57e1-4f63-9699-b8ca58038412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Flip the frame horizontally for a later selfie-view display\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the BGR image to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Hands\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    # Check if hands are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get handedness (left or right)\n",
    "            handedness = results.multi_handedness[0].classification[0].label\n",
    "\n",
    "            # Draw landmarks on the hand\n",
    "            mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Display handedness on the frame\n",
    "            cv2.putText(frame, f\"{handedness} hand\", (int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * frame.shape[1]),\n",
    "                                                       int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * frame.shape[0])),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Hand Tracking', frame)\n",
    "\n",
    "    # Exit the loop when 'ESC' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release the capture and destroy all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ac56c-cc3d-470b-8375-8bebf013c135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
